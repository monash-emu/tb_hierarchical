{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import get_tb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"start_time\": 1850,\n",
    "    \"end_time\": 2050,\n",
    "    \"seed\": 100,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies_dict = {\n",
    "    \"majuro\": {\n",
    "        \"pop_size\": 27797,\n",
    "    },\n",
    "    \"study_2\": {\n",
    "        \"pop_size\": 1.e6,\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_tb_model(model_config, studies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Study-specific parameters\n",
    "    'transmission_rateXmajuro': 10,\n",
    "    'transmission_rateXstudy_2': 10,\n",
    "\n",
    "    'lifelong_activation_riskXmajuro': .15,\n",
    "    'lifelong_activation_riskXstudy_2': .10,\n",
    "    'prop_early_among_activatorsXmajuro': .90,\n",
    "    'prop_early_among_activatorsXstudy_2': .90,\n",
    "\n",
    "    'current_passive_detection_rate': 1.,\n",
    "\n",
    "    # Universal parameters\n",
    "    'mean_duration_early_latent': .5,\n",
    "    'rr_reinfection_latent_late': .2,\n",
    "    'rr_reinfection_recovered': 1.,\n",
    "    'self_recovery_rate': .2,\n",
    "    'tb_death_rate': .2,\n",
    "    'tx_duration': .5,\n",
    "    'tx_prop_death': .04\n",
    "}\n",
    "model.run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_df = model.get_derived_outputs_df()\n",
    "# do_df[['ltbi_propXstudy_1', 'ltbi_propXstudy_2']].plot()\n",
    "# do_df[['populationXstudy_1', 'populationXstudy_2']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_df[['ltbi_propXmajuro']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival import priors as esp\n",
    "from estival import targets as est\n",
    "from estival.model import BayesianCompartmentalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priors(studies_dict):\n",
    "\n",
    "    priors = [\n",
    "        esp.UniformPrior(\"current_passive_detection_rate\", [.1, 10.]),\n",
    "    ]\n",
    "\n",
    "    hyper_mean_lifelong = esp.UniformPrior(\"hyper_mean_lifelong\", [0., 1.])\n",
    "    hyper_sd_lifelong = esp.UniformPrior(\"hyper_sd_lifelong\", [0., 10.])\n",
    "    hyper_mean_early = esp.UniformPrior(\"hyper_mean_early\", [0., 1.])\n",
    "    hyper_sd_early = esp.UniformPrior(\"hyper_sd_early\", [0., 10.])\n",
    "    for study in studies_dict:\n",
    "        priors.extend(\n",
    "            [\n",
    "                esp.UniformPrior(f\"transmission_rateX{study}\", [1., 30.]),\n",
    "\n",
    "                # the two priors below will eventually be TruncNormal distributions linked through hyper-prior distributions (uniforms) \n",
    "                esp.TruncNormalPrior(f\"lifelong_activation_riskX{study}\", hyper_mean_lifelong, hyper_sd_lifelong, [0., 1.]),\n",
    "                esp.TruncNormalPrior(f\"prop_early_among_activatorsX{study}\", hyper_mean_early, hyper_sd_early, [0., 1.]),\n",
    "\n",
    "            ]\n",
    "        )\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = get_priors(studies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "targets = [\n",
    "    est.NormalTarget(\"ltbi_propXmajuro\", data=pd.Series(data=[.38], index=[2018]), stdev=esp.UniformPrior(\"std_ltbi\", [.01, 0.5])),\n",
    "    est.NormalTarget(\"tb_prevalence_per100kXmajuro\", data=pd.Series(data=[1366], index=[2018]), stdev=esp.UniformPrior(\"std_tb\", [10., 1000.])),\n",
    "    est.NormalTarget(\"raw_notificationsXmajuro\", data=pd.Series(data=[100], index=[2015]), stdev=esp.UniformPrior(\"std_not\", [1., 100.])),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng\n",
    "from estival.wrappers.nevergrad import optimize_model\n",
    "\n",
    "def calibrate_with_opti(bcm, n_iter, opt_class=ng.optimizers.NGOpt):\n",
    "    \n",
    "    orunner = optimize_model(bcm, opt_class=opt_class)\n",
    "    rec = orunner.minimize(n_iter)\n",
    "    mle_params = rec.value[1]\n",
    "\n",
    "    return mle_params\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualise_mle_fit(bcm, mle_params):\n",
    "    print(\"Running model with MLE parameters...\")\n",
    "    res = bcm.run(mle_params)\n",
    "    print(\"... run completed.\")\n",
    "    for target in bcm.targets:\n",
    "        plt.figure()\n",
    "        bcm.targets[target].data.plot(style='.')\n",
    "        res.derived_outputs[target].plot()\n",
    "        plt.title(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm = BayesianCompartmentalModel(model, params, priors, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mle_params = calibrate_with_opti(bcm, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise_mle_fit(bcm, mle_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from estival.wrappers import pymc as epm\n",
    "\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    # This is all you need - a single call to use_model\n",
    "    variables = epm.use_model(bcm)\n",
    "    idata = pm.sample(step=[pm.DEMetropolis(variables)], draws=100, tune=0,cores=4,chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
