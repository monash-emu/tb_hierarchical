{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import model as m\n",
    "\n",
    "reload(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"start_time\": 1850,\n",
    "    \"end_time\": 2050,\n",
    "    \"seed\": 100,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies_dict = {\n",
    "    \"majuro\": {\n",
    "        \"pop_size\": 27797,\n",
    "    },\n",
    "    \"study_2\": {\n",
    "        \"pop_size\": 50000,\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m.get_tb_model(model_config, studies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Study-specific parameters\n",
    "    'transmission_rateXmajuro': 10,\n",
    "    'transmission_rateXstudy_2': 10,\n",
    "\n",
    "    'lifelong_activation_riskXmajuro': .15,\n",
    "    'lifelong_activation_riskXstudy_2': .10,\n",
    "    'prop_early_among_activatorsXmajuro': .90,\n",
    "    'prop_early_among_activatorsXstudy_2': .90,\n",
    "\n",
    "    'current_passive_detection_rate': 1.,\n",
    "\n",
    "    # Universal parameters\n",
    "    'mean_duration_early_latent': .5,\n",
    "    'rr_reinfection_latent_late': .2,\n",
    "    'rr_reinfection_recovered': 1.,\n",
    "    'self_recovery_rate': .2,\n",
    "    'tb_death_rate': .2,\n",
    "    'tx_duration': .5,\n",
    "    'tx_prop_death': .04\n",
    "}\n",
    "model.run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_df = model.get_derived_outputs_df()\n",
    "# do_df[['ltbi_propXstudy_1', 'ltbi_propXstudy_2']].plot()\n",
    "# do_df[['populationXmajuro', 'populationXstudy_2']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_df[['ltbi_propXmajuro']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival import priors as esp\n",
    "from estival import targets as est\n",
    "from estival.model import BayesianCompartmentalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priors(studies_dict):\n",
    "\n",
    "    # Define hyper-prior distributions\n",
    "    hyper_mean_lifelong = esp.UniformPrior(\"hyper_mean_lifelong\", [0., 1.])\n",
    "    # hyper_sd_lifelong = esp.UniformPrior(\"hyper_sd_lifelong\", [0., 10.])\n",
    "    # hyper_mean_early = esp.UniformPrior(\"hyper_mean_early\", [0., 1.])\n",
    "    # hyper_sd_early = esp.UniformPrior(\"hyper_sd_early\", [0., 10.])\n",
    "    \n",
    "    # Initialise the list of priors with \"universal\" priors and hyper-priors\n",
    "    priors = [\n",
    "        esp.UniformPrior(\"current_passive_detection_rate\", [.1, 10.]),\n",
    "        hyper_mean_lifelong,\n",
    "        # hyper_sd_lifelong,\n",
    "        # hyper_mean_early,\n",
    "        # hyper_sd_early\n",
    "    ]\n",
    "    \n",
    "    # Complete the list of priors using study-specific priors\n",
    "    for study in studies_dict:\n",
    "        priors.extend(\n",
    "            [\n",
    "                esp.UniformPrior(f\"transmission_rateX{study}\", [1., 15.]),\n",
    "\n",
    "                # the two priors below linked through the previously defined hyper-prior distributions \n",
    "\n",
    "                # esp.TruncNormalPrior(f\"lifelong_activation_riskX{study}\", hyper_mean_lifelong, hyper_sd_lifelong, [0., 1.]),\n",
    "                esp.TruncNormalPrior(f\"lifelong_activation_riskX{study}\", hyper_mean_lifelong, .01, [0., 1.]),\n",
    "\n",
    "\n",
    "                # esp.TruncNormalPrior(f\"prop_early_among_activatorsX{study}\", hyper_mean_early, hyper_sd_early, [0., 1.]),\n",
    "            ]\n",
    "        )\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = get_priors(studies_dict)\n",
    "prior_list = [p.name for p in priors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "targets = [\n",
    "    est.NormalTarget(\"ltbi_propXmajuro\", data=pd.Series(data=[.38], index=[2018]), stdev=esp.UniformPrior(\"std_ltbi\", [.001, .1])),\n",
    "    est.NormalTarget(\"tb_prevalence_per100kXmajuro\", data=pd.Series(data=[1366], index=[2018]), stdev=esp.UniformPrior(\"std_tb\", [10., 250.])),\n",
    "    est.NormalTarget(\"raw_notificationsXmajuro\", data=pd.Series(data=[100], index=[2015]), stdev=esp.UniformPrior(\"std_not\", [1., 25.])),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng\n",
    "from estival.wrappers.nevergrad import optimize_model\n",
    "\n",
    "def calibrate_with_opti(bcm, n_iter, opt_class=ng.optimizers.NGOpt):\n",
    "    \n",
    "    orunner = optimize_model(bcm, opt_class=opt_class)\n",
    "    rec = orunner.minimize(n_iter)\n",
    "    mle_params = rec.value[1]\n",
    "\n",
    "    return mle_params\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualise_mle_fit(bcm, mle_params):\n",
    "    print(\"Running model with MLE parameters...\")\n",
    "    res = bcm.run(mle_params)\n",
    "    print(\"... run completed.\")\n",
    "    for target in bcm.targets:\n",
    "        plt.figure()\n",
    "        bcm.targets[target].data.plot(style='.')\n",
    "        res.derived_outputs[target].plot()\n",
    "        plt.title(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m.get_tb_model(model_config, studies_dict)\n",
    "bcm = BayesianCompartmentalModel(model, params, priors, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mle_params = calibrate_with_opti(bcm, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise_mle_fit(bcm, mle_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from estival.wrappers import pymc as epm\n",
    "\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    variables = epm.use_model(bcm)\n",
    "    idata = pm.sample(step=[pm.DEMetropolisZ(variables)], draws=20000, tune=2000,cores=4,chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise traces and posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = 10000\n",
    "full_runs_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import arviz as az\n",
    "\n",
    "\n",
    "def make_post_mc_plots(idata, burn_in, output_folder=None):\n",
    "    az.rcParams[\"plot.max_subplots\"] = 60 # to make sure all parameters are included in trace plots\n",
    "\n",
    "    if output_folder:\n",
    "        output_folder_path = Path(output_folder) / \"mc_outputs\"\n",
    "        output_folder_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    chain_length = idata.sample_stats.sizes['draw']\n",
    "\n",
    "    # Traces (including burn-in)\n",
    "    # az.plot_trace(idata, figsize=(16, 3.0 * len(idata.posterior)), compact=False);\n",
    "    # plt.subplots_adjust(hspace=.7)\n",
    "    # if output_folder:\n",
    "    #     plt.savefig(output_folder_path / \"mc_traces.jpg\", facecolor=\"white\", bbox_inches='tight')\n",
    "    #     plt.close()\n",
    "\n",
    "    # burn data\n",
    "    burnt_idata = idata.sel(draw=range(burn_in, chain_length))  # Discard burn-in\n",
    "\n",
    "    # Traces (after burn-in)\n",
    "    az.plot_trace(burnt_idata, figsize=(16, 3.0 * len(idata.posterior)), compact=False);\n",
    "    plt.subplots_adjust(hspace=.7)\n",
    "    if output_folder:\n",
    "        plt.savefig(output_folder_path / \"mc_traces_postburnin.jpg\", facecolor=\"white\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Posteriors (excluding burn-in)\n",
    "    az.plot_posterior(burnt_idata);\n",
    "    if output_folder:\n",
    "        plt.savefig(output_folder_path / \"mc_posteriors_postburnin.png\", facecolor=\"white\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # ESS (excluding burn-in)\n",
    "    # raw_ess_df = az.ess(burnt_idata).to_dataframe()\n",
    "    # ess_df = raw_ess_df.drop(columns=\"random_process.delta_values\").loc[0]\n",
    "    # for i in range(len(raw_ess_df)):\n",
    "    #     ess_df[f\"random_process.delta_values[{i}]\"] = raw_ess_df['random_process.delta_values'][i]\n",
    "    # if output_folder:\n",
    "    #     ess_df.to_csv(output_folder_path / \"mc_ess.csv\", header=[\"ESS\"])\n",
    "\n",
    "    # R_hat plot (excluding burn-in)\n",
    "    # raw_rhat_df = az.rhat(burnt_idata).to_dataframe()\n",
    "    # rhat_df = raw_rhat_df.drop(columns=\"random_process.delta_values\").loc[0]\n",
    "    # for i in range(len(raw_rhat_df)):\n",
    "    #     rhat_df[f\"random_process.delta_values[{i}]\"] = raw_rhat_df['random_process.delta_values'][i]\n",
    "    # axis = rhat_df.plot.barh(xlim=(1.,1.105))\n",
    "    # axis.vlines(x=1.05,ymin=-0.5, ymax=len(rhat_df), linestyles=\"--\", color='orange')\n",
    "    # axis.vlines(x=1.1,ymin=-0.5, ymax=len(rhat_df), linestyles=\"-\",color='red')    \n",
    "    # if output_folder:\n",
    "    #     plt.savefig(output_folder_path / \"r_hats.jpg\", facecolor=\"white\", bbox_inches='tight')\n",
    "    #     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_post_mc_plots(idata, burn_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot outputs with uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estival.sampling import tools as esamp\n",
    "\n",
    "def extract_sample_subset(idata, n_samples, burn_in, chain_filter: list = None):\n",
    "    chain_length = idata.sample_stats.sizes['draw']\n",
    "    burnt_idata = idata.sel(draw=range(burn_in, chain_length))  # Discard burn-in\n",
    "    \n",
    "    return az.extract(burnt_idata, num_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "full_run_params = extract_sample_subset(idata, full_runs_samples, burn_in)  \n",
    "full_runs = esamp.model_results_for_samples(full_run_params, bcm, include_extras=False)\n",
    "\n",
    "unc_df = esamp.quantiles_for_results(full_runs.results, [.025, .25, .5, .75, .975])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def plot_model_fit_with_uncertainty(axis, uncertainty_df, output_name, bcm, include_legend=True):\n",
    "\n",
    "    # update_rcparams() \n",
    "   \n",
    "    df = uncertainty_df[output_name]\n",
    "\n",
    "    if output_name in bcm.targets:\n",
    "        t = copy(bcm.targets[output_name].data)\n",
    "        axis.scatter(list(t.index), t, marker=\".\", color='black', label='observations', zorder=11, s=5.)\n",
    "\n",
    "    colour = (0.2, 0.2, 0.8)   \n",
    "\n",
    "    time = df.index\n",
    "    axis.plot(time, df[0.5], color=colour, zorder=10, label=\"model (median)\")\n",
    "\n",
    "    axis.fill_between(\n",
    "        time, \n",
    "        df[0.25], df[0.75], \n",
    "        color=colour, \n",
    "        alpha=0.5, \n",
    "        edgecolor=None,\n",
    "        label=\"model (IQR)\"\n",
    "    )\n",
    "    axis.fill_between(\n",
    "        time, \n",
    "        df[0.025], df[0.975],\n",
    "        color=colour, \n",
    "        alpha=0.3,\n",
    "        edgecolor=None,\n",
    "        label=\"model (95% CI)\",\n",
    "    )\n",
    "\n",
    "    if output_name == \"transformed_random_process\":\n",
    "        axis.set_ylim((0., axis.get_ylim()[1]))\n",
    "\n",
    "    \n",
    "    # x_min = bcm.targets[\"population\"].data.index.min()\n",
    "    # axis.set_xlim((x_min, axis.get_xlim()[1]))\n",
    "\n",
    "    # axis.tick_params(axis=\"x\", labelrotation=45)\n",
    "    title = output_name # if output_name not in title_lookup else title_lookup[output_name]\n",
    "\n",
    "    axis.set_ylabel(title)\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    if include_legend:\n",
    "        plt.legend(markerscale=2.)\n",
    "    # axis.yaxis.set_major_formatter(tick.FuncFormatter(y_fmt))\n",
    "\n",
    "    # return x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_outputs = [t.name for t in targets]\n",
    "\n",
    "for output in selected_outputs:\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plot_model_fit_with_uncertainty(ax, unc_df, output, bcm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_post_prior_comparison(\n",
    "    idata: az.InferenceData,\n",
    "    req_vars: list, #List[str],\n",
    "    priors: list, #List[dist.Distribution],\n",
    "    req_grid=None,\n",
    "    req_size=None,\n",
    ") -> plt.figure:\n",
    "    \"\"\"Plot comparison of calibration posterior estimates\n",
    "    for parameters against their prior distributions.\n",
    "\n",
    "    Args:\n",
    "        idata: Calibration inference data\n",
    "        req_vars: Names of the parameters to plot\n",
    "        priors: Prior distributions for the parameters\n",
    "        req_grid: Dimensions of the subplot\n",
    "        req_size: Figure size request\n",
    "\n",
    "    Returns:\n",
    "        The figure\n",
    "    \"\"\"\n",
    "    grid = req_grid if req_grid else [1, len(req_vars)]\n",
    "    size = req_size if req_size else None\n",
    "    fig = az.plot_density(idata, var_names=req_vars, shade=0.3, grid=grid, figsize=size, hdi_prob=1.)\n",
    "    for i_ax, ax in enumerate(fig.ravel()):\n",
    "        ax_limits = ax.get_xlim()\n",
    "        param = ax.title.get_text().split(\"\\n\")[0]\n",
    "        if param:\n",
    "            x_vals = np.linspace(*ax_limits, 50)\n",
    "            distri = priors[i_ax]\n",
    "            # if len(distri.batch_shape) == 0:\n",
    "\n",
    "            if type(distri) != esp.TruncNormalPrior:\n",
    "                y_vals = np.exp(distri.logpdf(x_vals))\n",
    "                # else:\n",
    "                #     y_vals = np.exp(distri.log_prob(x_vals[:, None])[:, 0])\n",
    "                # y_vals *= ax.get_ylim()[1] # / max(y_vals)\n",
    "                ax.fill_between(x_vals, y_vals, color=\"k\", alpha=0.2, linewidth=2)\n",
    "    # ax.figure.suptitle(country, fontsize=30, y=1.0)\n",
    "    return ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_post_prior_comparison(idata, list(bcm.priors.keys()), list(bcm.priors.values()), req_grid=[3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
