{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbh import runner_tools as rt \n",
    "from tbh import plotting as pl\n",
    "\n",
    "from importlib import reload\n",
    "reload(rt);\n",
    "reload(pl);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies_dict = rt.DEFAULT_STUDIES_DICT\n",
    "params = rt.get_full_default_params(studies_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, do_df = rt.model_single_run(rt.DEFAULT_MODEL_CONFIG, studies_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_df[['ltbi_propXmajuro']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration and full runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis config\n",
    "tune = 50\n",
    "draws = 100\n",
    "\n",
    "# Full runs config\n",
    "burn_in = int(draws / 2.) # 10000\n",
    "full_runs_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcm = rt.get_bcm_object(rt.DEFAULT_MODEL_CONFIG, studies_dict, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = rt.run_metropolis_calibration(bcm, draws=draws, tune=tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "rhats = az.rhat(idata)\n",
    "burnt_rhats = az.rhat(idata.sel(draw=range(burn_in, idata.sample_stats.sizes['draw'])))\n",
    "print(f\"Max R_hat for full chains: {rhats.to_array().max().item()}\")\n",
    "print(f\"Max R_hat for burnt chains: {burnt_rhats.to_array().max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_runs, unc_df = rt.run_full_runs(bcm, idata, burn_in, full_runs_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise traces and posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot_traces(idata, burn_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot_post_prior_comparison(idata, burn_in, list(bcm.priors.keys()), list(bcm.priors.values()), n_col=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot outputs with uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_outputs = bcm.targets.keys()\n",
    "\n",
    "for output in selected_outputs:\n",
    "    fig, ax = plt.subplots()\n",
    "    pl.plot_model_fit_with_uncertainty(ax, unc_df, output, bcm, x_min=2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
